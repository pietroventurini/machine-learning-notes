{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "disciplinary-article",
   "metadata": {},
   "source": [
    "# Optimization Algorithms\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. [**Prerequisites**](#Prerequisites)  \n",
    "    1. [Exponentially Weighted Average](#Exponentially-Weighted-Average)\n",
    "2. [**Optimization Algorithms**](#Optimization-Algorithms)  \n",
    "    1. [Momentum](#Momentum)  \n",
    "    2. [Nesterov Accelerated Gradient](#Nesterov-Accelerated-Gradient)  \n",
    "    3. [RMSProp](#RMSProp)  \n",
    "    4. [Adam](#Adam) \n",
    "3. [**Common Practices**](#Common-Practices)\n",
    "    1. [Dynamic learning rate](#Dynamic-learning-rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forward-finish",
   "metadata": {},
   "source": [
    "# Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composite-cloud",
   "metadata": {},
   "source": [
    "## Exponentially Weighted Average\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sorted-kansas",
   "metadata": {},
   "source": [
    "# Optimization Algorithms\n",
    "\n",
    "We can use variants of the stochastic or mini-batch gradient descent that may help to speed up learning and escape local minima. One of these techniques is the gradient descent with momentum. Two more popular optimization algorithms that have been shown to work well on a wide range of neural network architectures are RMSProp and Adam."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unable-titanium",
   "metadata": {
    "colab_type": "text",
    "id": "GDl7-AMNprYE"
   },
   "source": [
    "## Momentum\n",
    "\n",
    "There exist several euristics that can be used to avoid getting stuck in local minima and may help accelerate the learning. For example we can include a **weight momentum** in the weight update. The basic idea is to compute an **exponentially weighted average** (governed by a parameter $\\beta$) of the gradients and to use it to update our weights instead. Assume we are performing mini-batch gradient descent, and consider the update step for the $l$-th layer (we'll omit the superscript denoting the layer in the next lines). First we compute the derivatives $\\mathrm{d}W$ and $\\mathrm{d}\\mathbf{b}$ of the loss function with respect to that layer's weights, on the current mini-batch. Then we update the weights in this way:\n",
    "\n",
    "$$V_{\\mathrm{d}W} = \\beta V_{\\mathrm{d}W} + (1-\\beta) \\mathrm{d}W$$\n",
    "\n",
    "$$V_{\\mathrm{d}b} = \\beta V_{\\mathrm{d}b} + (1-\\beta) \\mathrm{d}b$$\n",
    "\n",
    "$$W = W - \\alpha V_{\\mathrm{d}W}$$\n",
    "\n",
    "$$b = b - \\alpha V_{\\mathrm{d}b}$$\n",
    "\n",
    "In this way we can smooth out the steps of gradient descent and follow a more straightforward path. Weight momentum can also be interpreted by making an analogy with physics: the current value of the weights represents the position of a physical object rolling down a surface (defined by the cost function). The term $\\mathrm{d}W$ can be thought as an acceleration and the term $V_{\\mathrm{d}W}$ as a velocity. The hyperparameter $\\beta$, which is smaller than $1$, represents a _friction_ and prevents the object from speeding up without limit, but rather than taking each step independently from the previously taken ones, the object can gain momentum from and, eventually, escape a local minimum.\n",
    "\n",
    "In practice $V_{\\mathrm{d}W}$ is a matrix of the same dimension of $W$, $V_{\\mathrm{d}b}$ is a vector of the same dimension of $b$, and they are both initialized to zero. Tipically, $\\beta$ is initialized to some value around $0.9$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "everyday-overhead",
   "metadata": {},
   "source": [
    "## Nesterov Accelerated Gradient\n",
    "\n",
    "Nesterov Accelerated Gradient is slighlty different than momentum in the sense that we kind of \"look into the future\" to see how much momentum is required. The update equations become:\n",
    "\n",
    "$$\\delta^{(k+1)} = -\\eta \\nabla L(W^{(k)} + \\alpha \\delta^{(k)}) + \\alpha\\delta^{(k)}$$\n",
    "\n",
    "$$W^{(k+1)} = W^{(k)} + \\delta^{(k+1)}$$\n",
    "\n",
    "The same holds also for $b$. With Nesterov momentum, first we move in the previous accumulated gradient computed the iteration before (from $W^{(k)}$ to $W^{(k)} + \\alpha\\delta^{(k)}$, then we compute the gradient in that point ($-\\eta \\nabla L(W^{(k)} + \\alpha \\delta^{(k)})$) and finally make a correction.\n",
    "\n",
    "<img src=\"images/neural_networks/Nesterov.png\" style=\"width:40em; display: block; margin-left: auto; margin-right: auto;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "purple-pathology",
   "metadata": {},
   "source": [
    "## RMSProp\n",
    "\n",
    "Root Mean Square Propagation ([RMSProp](http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf)) is quite similar to weight momentum, but it divides the gradient by a running weighted average. The main reason behind this method is that the fact that the magnitude of the gradient for different weights may change during the learning makes it difficult to choose a single global learning rate.\n",
    "\n",
    "$$S_{\\mathrm{d}W} = \\beta_2 S_{\\mathrm{d}W} + (1-\\beta_2) \\mathrm{d}W^2$$\n",
    "\n",
    "$$S_{\\mathrm{d}b} = \\beta_2 S_{\\mathrm{d}b} + (1-\\beta_2) \\mathrm{d}b^2$$\n",
    "\n",
    "$$W = W - \\alpha \\frac{\\mathrm{d}W}{\\sqrt{S_{\\mathrm{d}W}}+\\varepsilon}$$\n",
    "\n",
    "$$b = b - \\alpha \\frac{\\mathrm{d}b}{\\sqrt{S_{\\mathrm{d}b}}+\\varepsilon}$$\n",
    "\n",
    "Note that the squaring operation is computed element-wise, and we used different letters $S_{\\mathrm{d}W}$ and $\\beta_2$ than with momentum, because with Adam we are going to combine both momentum and RMSProp. $\\varepsilon$ is a small term (in practice we can set it to $10^{-8}$) that prevents dividing by some quantity close to zero that would make the numerator explode. Note also that, differently from weight momentum, here we dump out the oscillations by dividing by a term which is proportional to the width of the step (to the derivative of the loss function with respect to $W$ or $b$), therefore, wider steps (steps in a direction in which the function is steeper) will be dump out more than narrow steps (steps in a direction in which the function is flatter). In other words, every parameter is weighted by a different learning rate.\n",
    "\n",
    "A consequence of this is that we can use a larger learning rate $\\alpha$ without diverging in the steepest directions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spiritual-applicant",
   "metadata": {},
   "source": [
    "## Adam\n",
    "\n",
    "Adaptive moment estimation (Adam) puts together weight momentum and RMSProp. The parameters are initialized to zero.\n",
    "\n",
    "$$V_{\\mathrm{d}W}=0, \\quad S_{\\mathrm{d}W}=0, \\quad V_{\\mathrm{d}b}=0, \\quad S_{\\mathrm{d}b}=0.$$\n",
    "\n",
    "Then, on iteration $t$:\n",
    "- Compute $\\mathrm{d}W$ and $\\mathrm{d}b$ using the current mini-batch \n",
    "- Compute Momentum exponentially weighted average:  \n",
    "    - $V_{\\mathrm{d}W}=\\beta_1 V_{\\mathrm{d}W} + (1-\\beta_1)\\mathrm{d}W$  \n",
    "    - $V_{\\mathrm{d}b}=\\beta_1 V_{\\mathrm{d}b} + (1-\\beta_1)\\mathrm{d}b$  \n",
    "- Compute the RMSProp update terms:\n",
    "    - $S_{\\mathrm{d}W}=\\beta_2 S_{\\mathrm{d}W} + (1-\\beta_2)\\mathrm{d}W^2$  \n",
    "    - $S_{\\mathrm{d}b}=\\beta_2 S_{\\mathrm{d}b} + (1-\\beta_2)\\mathrm{d}b^2$  \n",
    "- Perform the bias correction:\n",
    "    - $V_{\\mathrm{d}W}^{corr} = \\frac{V_{\\mathrm{d}W}}{1-\\beta_1^t}$  \n",
    "    - $V_{\\mathrm{d}b}^{corr} = \\frac{V_{\\mathrm{d}b}}{1-\\beta_1^t}$  \n",
    "    - $S_{\\mathrm{d}W}^{corr} = \\frac{S_{\\mathrm{d}W}}{1-\\beta_2^t}$  \n",
    "    - $S_{\\mathrm{d}W}^{corr} = \\frac{S_{\\mathrm{d}W}}{1-\\beta_2^t}$  \n",
    "- Update the weights:\n",
    "    - $W := W - \\alpha \\frac{V_{\\mathrm{d}W}^{corr}}{\\sqrt{S_{\\mathrm{d}W}^{corr}}+\\varepsilon}$\n",
    "    - $b := b - \\alpha \\frac{V_{\\mathrm{d}b}^{corr}}{\\sqrt{S_{\\mathrm{d}b}^{corr}}+\\varepsilon}$\n",
    "    \n",
    "This algorithm has some hyperparameters that have to be tuned, and others that are tipically initialized to some common values:\n",
    "- Learning rate $\\alpha$ needs to be tuned (we could try few values and choose the one yielding the best result, or adopt learning rate decay).\n",
    "- $\\beta_1 = 0.9$\n",
    "- $\\beta_2 = 0.999$\n",
    "- $\\varepsilon = 10^{-8}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comprehensive-duncan",
   "metadata": {},
   "source": [
    "# Common practices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "united-mechanism",
   "metadata": {
    "colab_type": "text",
    "id": "1GHn2pCQqXzU"
   },
   "source": [
    "### Dynamic learning rate\n",
    "\n",
    "Instead of using a fixed, chosen a priori, learning rate, $\\alpha$ is often replaced by a learning rate that decreases over time, for example:\n",
    "\n",
    "$$\\alpha = \\frac{\\alpha_0}{1 + \\text{decay_rate} \\cdot \\text{epoch_num}}$$\n",
    "\n",
    "where $\\alpha_0$ is the initial learning rate.\n",
    "\n",
    "There exist other learning rate decay methods, for instance:\n",
    "\n",
    "- **Exponential decay**:\n",
    "\n",
    "$$\\alpha = k^{\\text{epoch_num}}\\cdot \\alpha_0$$\n",
    "\n",
    "where $k$ is a constant, e.g. $k=0.95$.\n",
    "\n",
    "- **Based on epoch number:**\n",
    "\n",
    "$$\\alpha = \\frac{k}{\\sqrt{\\text{epoch_num}}} \\cdot \\alpha_0$$\n",
    "\n",
    "where $k$ is a constant.\n",
    "\n",
    "- **Based on batch size:**\n",
    "\n",
    "$$\\alpha = \\frac{k}{\\sqrt{\\text{batch_size}}} \\cdot \\alpha_0$$\n",
    "\n",
    "where $k$ is a constant.\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
